{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "import sklearn.preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    ps =PorterStemmer()\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(ps.stem(w))\n",
    "    \n",
    "    \n",
    "    return filtered_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    e = xml.etree.ElementTree.parse(filepath).getroot()\n",
    "    for textx in e.find('text'):\n",
    "         # return preproc(textx.text.lower())\n",
    "        return textx.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trainfile():\n",
    "    list_text = []\n",
    "    for filename in os.listdir('dataset tugas/Training set/'):\n",
    "        list_text.append(read_file('dataset tugas/Training set/'+ filename))\n",
    "    return list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_testfile():\n",
    "    list_text = []\n",
    "    for filename in os.listdir('dataset tugas/Testing set/'):\n",
    "        list_text.append(read_file('dataset tugas/Testing set/'+ filename) )\n",
    "    return list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_preprocessing(result):\n",
    "    text = []\n",
    "    for i in result:\n",
    "        textx = ''\n",
    "        for j in i:\n",
    "            textx = textx + ' ' + j\n",
    "        text.append(textx)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'General Motors Corp executives said they were not aware of any involvement by current GM employees in an investigation of alleged kickbacks demanded by former Volkswagen AG production chief J. Ignacio Lopez de Arriortua and his followers.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = read_trainfile()\n",
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTrain = pd.read_csv('dataset tugas/label/Training set.txt', delimiter= ' ',sep=\"\\t\", header=None)\n",
    "y = np.asarray(labelTrain[1])\n",
    "y[y == 'YES'] = 1\n",
    "y[y == 'NO'] = 0\n",
    "\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = read_testfile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf = text_clf.fit(result, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTrain = pd.read_csv('dataset tugas/label/Testing set.txt', delimiter= ' ',sep=\"\\t\", header=None)\n",
    "y_answer = np.asarray(labelTrain[1])\n",
    "y_answer[y_answer == 'YES'] = 1\n",
    "y_answer[y_answer == 'NO'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.52173913043478"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benar= 0\n",
    "for i in range(len(y_answer)):\n",
    "    if (predicted[i] == y_answer[i]):\n",
    "        benar +=1\n",
    "acc = benar / len(y_answer) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clfx = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MLPClassifier()),\n",
    "])\n",
    "text_clfx = text_clfx.fit(result, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clfx.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.86956521739131"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benar= 0\n",
    "for i in range(len(y_answer)):\n",
    "    if (predicted[i] == y_answer[i]):\n",
    "        benar +=1\n",
    "acc = benar / len(y_answer) * 100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
